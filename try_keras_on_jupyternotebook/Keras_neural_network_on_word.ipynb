{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a document that tries keras on jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T01:12:33.754031Z",
     "start_time": "2017-11-14T01:12:33.737939Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import re\n",
    "from keras.models import Sequential, Model, load_model, save_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.layers import GaussianNoise, BatchNormalization, Dropout\n",
    "from keras.layers import Activation, merge, Input, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import Callback, LambdaCallback, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T00:25:49.390643Z",
     "start_time": "2017-11-14T00:25:49.258264Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_desired_letter(char):\n",
    "    return ord(char) >= 97 and ord(char) < 123 or ord(char) >= 48 and ord(char) < 58 or ord(char) == ord(\" \")\n",
    "\n",
    "\n",
    "def get_train_data(train_portion):\n",
    "    # load the dataset but only keep the top n words, zero the rest\n",
    "    train_data = pd.read_csv(\"input/kickstarter_train.csv\")\n",
    "    train_texts_and_results = train_data.iloc[:, [2, -1]]\n",
    "    # get split point for train and test data\n",
    "    split_point = int(train_portion * len(train_data))\n",
    "    # do preliminary preprocessing:remove all symbols\n",
    "    train_data[\"desc\"] = [[char for char in str(text).lower() if is_desired_letter(char)] for\n",
    "                          text in train_data[\"desc\"]]\n",
    "    train_data[\"desc\"] = [''.join(text).split() for text in train_data[\"desc\"]]\n",
    "    # remove too short desc\n",
    "    drop_index = []\n",
    "    for i in range(len(train_data)):\n",
    "        if len(train_data.iloc[i, 2]) <= 8:\n",
    "            drop_index.append(i)\n",
    "    train_data.drop(train_data.index[drop_index])\n",
    "    # get descriptions data\n",
    "    train_texts = np.array(train_data.iloc[:split_point, 2])\n",
    "    test_texts = np.array(train_data.iloc[split_point:, 2])\n",
    "    # get num data\n",
    "    train_num = np.array(train_data.iloc[:split_point, [3, 12]])\n",
    "    test_num = np.array(train_data.iloc[split_point:, [3, 12]])\n",
    "    # get result data\n",
    "    train_results = np.array(train_data.iloc[:split_point, -1])\n",
    "    test_results = np.array(train_data.iloc[split_point:, -1])\n",
    "    \n",
    "    return train_texts, train_num, train_results, test_texts, test_num, test_results\n",
    "\n",
    "\n",
    "def get_bad_word_portion(data):\n",
    "    bad_word_num = 0.0\n",
    "    all_word = 0.0\n",
    "    for text in data:\n",
    "        for word in text:\n",
    "            all_word += 1\n",
    "            if word not in all_words:\n",
    "                bad_word_num += 1\n",
    "    return bad_word_num / all_word\n",
    "\n",
    "\n",
    "def convert_to_onehot(data, num_features):\n",
    "    new_data = []\n",
    "    for item in data:\n",
    "        new_data.append(np_utils.to_categorical(item, num_classes=num_features))\n",
    "    return np.array(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T00:26:02.512620Z",
     "start_time": "2017-11-14T00:25:50.820679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data grabbed\n",
      "0.02938531311469891\n",
      "tokenizing and normalizing is done\n"
     ]
    }
   ],
   "source": [
    "# get training testing data from disk\n",
    "train_data_portion = 0.9\n",
    "trainX_desc, trainX_num, trainY, testX_desc, testX_num, testY = get_train_data(train_data_portion)\n",
    "print(\"data grabbed\")\n",
    "\n",
    "# convert char to int, and \n",
    "all_words = set([word for text in trainX_desc for word in text])\n",
    "n_vacab = len(all_words) + 1\n",
    "word_to_int = dict((word, float(i+1)) for i, word in enumerate(all_words))\n",
    "trainX_desc = [[word_to_int[word] for word in text] for text in trainX_desc]\n",
    "# print bad word portion for test data before tokenization\n",
    "print(get_bad_word_portion(testX_desc))\n",
    "testX_desc = [[word_to_int[word] for word in text if word in all_words] for text in testX_desc]\n",
    "\n",
    "print(\"tokenizing and normalizing is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T00:26:07.874215Z",
     "start_time": "2017-11-14T00:26:07.176878Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding finished\n"
     ]
    }
   ],
   "source": [
    "# preprocessing description data\n",
    "# truncate and pad input sequences\n",
    "max_desc_length = 40\n",
    "trainX_desc = sequence.pad_sequences(list(trainX_desc), maxlen=max_desc_length, truncating=\"post\")\n",
    "testX_desc = sequence.pad_sequences(list(testX_desc), maxlen=max_desc_length, truncating=\"post\")\n",
    "print(\"padding finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T00:26:14.092391Z",
     "start_time": "2017-11-14T00:26:14.087601Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # reshape trainX to multi_timestep single feature\n",
    "# time_steps = max_desc_length\n",
    "# num_features = 1\n",
    "# testX_desc = np.array(testX_desc)\n",
    "# testX_desc = testX_desc.reshape((-1, time_steps, num_features))\n",
    "# trainX_desc = np.array(trainX_desc)\n",
    "# trainX_desc = trainX_desc.reshape((-1, time_steps, num_features))\n",
    "# print(\"reshaping data with shape {}\".format(trainX_desc.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T06:20:03.933769Z",
     "start_time": "2017-11-14T06:20:03.622050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "embedding_28 (Embedding)     (None, 40, 64)            5240192   \n",
      "_________________________________________________________________\n",
      "gaussian_noise_16 (GaussianN (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 36, 64)            20544     \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 36, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 34, 64)            12352     \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 34, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 64)                69696     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,343,105\n",
      "Trainable params: 5,342,977\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "model building finished\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# generate model for descriptions\n",
    "model_input = Input(shape=(40,))\n",
    "x = model_input\n",
    "x = Embedding(input_dim=n_vacab, output_dim=64, input_length=40)(x)\n",
    "x = GaussianNoise(stddev=0.1)(x)\n",
    "x = Conv1D(filters=64, kernel_size=5, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv1D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"sigmoid\")(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "description_model = Model(inputs=[model_input], outputs=[x])\n",
    "\n",
    "# configurate model training\n",
    "description_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(\"model building finished\\n\", description_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T06:15:26.061413Z",
     "start_time": "2017-11-14T06:15:17.396902Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87584 samples, validate on 9732 samples\n",
      "Epoch 1/5\n",
      "15616/87584 [====>.........................] - ETA: 38s - loss: 0.2205 - acc: 0.9064"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-10672f950f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     description_model.fit(trainX_desc, trainY, epochs=5, batch_size=256, shuffle=True, \n\u001b[0;32m----> 5\u001b[0;31m                       verbose=1, validation_split=0.1, callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)])\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# see actual result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescription_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# do training\n",
    "epoch_num = 2\n",
    "for i in range(epoch_num):\n",
    "    description_model.fit(trainX_desc, trainY, epochs=5, batch_size=256, shuffle=True, \n",
    "                      verbose=1, validation_split=0.1, callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)])\n",
    "    # see actual result\n",
    "    scores = description_model.evaluate(testX_desc, testY, verbose=1)\n",
    "    print(\"Accuracy:{}\".format(np.array(scores)))\n",
    "    print(\"actual epoch num is: \", i)\n",
    "\n",
    "# save model\n",
    "filepath = \"description_model_weights.h5\"\n",
    "description_model.save_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T06:50:30.460239Z",
     "start_time": "2017-11-14T06:50:30.398830Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-f35851b33f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdata_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrainX_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_num_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtestX_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_num_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-221-f35851b33f9d>\u001b[0m in \u001b[0;36mpreprocess_num_data\u001b[0;34m(data_num)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# preprocessing input nums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_num_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata_num_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata_num_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_num_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# preprocessing input nums\n",
    "def preprocess_num_data(data_num):\n",
    "    data_num_0 = [float(item[0]) for item in data_num]\n",
    "    data_num_1 = [float(item[1]) for item in data_num]\n",
    "    max0 = np.array(data_num_0).max()\n",
    "    max1 = np.array(data_num_1).max()\n",
    "    data_num_0 = [item / max0 * 2 - 1 for item in data_num_0]\n",
    "    data_num_1 = [item / max1 * 2 - 1 for item in data_num_1]\n",
    "    data_num= zip(data_num_0, data_num_1)\n",
    "    data_num = np.array(data_num)\n",
    "\n",
    "trainX_num = preprocess_num_data(trainX_num)\n",
    "testX_num = preprocess_num_data(testX_num)\n",
    "print(testX_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T06:50:51.234492Z",
     "start_time": "2017-11-14T06:50:51.229260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(testX_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T06:20:07.410936Z",
     "start_time": "2017-11-14T06:20:07.111644Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 833\n",
      "Trainable params: 737\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "model building finished\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# generate model for num data\n",
    "model_input = Input(shape=(2,))\n",
    "x = model_input\n",
    "x = Dense(units=12, input_shape=(2,))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"sigmoid\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(units=1, activation=\"sigmoid\")(x)\n",
    "num_model = Model(inputs=[model_input], outputs=[x])\n",
    "\n",
    "# configure network for training\n",
    "num_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(\"model building finished\\n\", num_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T06:16:19.318886Z",
     "start_time": "2017-11-14T06:16:07.372196Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87584 samples, validate on 9732 samples\n",
      "Epoch 1/100\n",
      "87584/87584 [==============================] - 3s 40us/step - loss: 0.6284 - acc: 0.6632 - val_loss: 0.5365 - val_acc: 0.7758\n",
      "Epoch 2/100\n",
      "87584/87584 [==============================] - 1s 10us/step - loss: 0.5874 - acc: 0.6941 - val_loss: 0.5484 - val_acc: 0.7804\n",
      "Epoch 3/100\n",
      "87584/87584 [==============================] - 1s 9us/step - loss: 0.5622 - acc: 0.7140 - val_loss: 0.5399 - val_acc: 0.7915\n",
      "Epoch 4/100\n",
      "87584/87584 [==============================] - 1s 10us/step - loss: 0.5411 - acc: 0.7258 - val_loss: 0.5032 - val_acc: 0.8084\n",
      "Epoch 5/100\n",
      "87584/87584 [==============================] - 1s 9us/step - loss: 0.5305 - acc: 0.7307 - val_loss: 0.4970 - val_acc: 0.8040\n",
      "Epoch 6/100\n",
      "87584/87584 [==============================] - 1s 9us/step - loss: 0.5193 - acc: 0.7385 - val_loss: 0.4794 - val_acc: 0.8105\n",
      "Epoch 7/100\n",
      "87584/87584 [==============================] - 1s 9us/step - loss: 0.5078 - acc: 0.7463 - val_loss: 0.4799 - val_acc: 0.8157\n",
      "Epoch 8/100\n",
      "87584/87584 [==============================] - 1s 9us/step - loss: 0.5045 - acc: 0.7479 - val_loss: 0.4864 - val_acc: 0.8164\n",
      "Epoch 9/100\n",
      "87584/87584 [==============================] - 1s 10us/step - loss: 0.5049 - acc: 0.7488 - val_loss: 0.4917 - val_acc: 0.8242\n"
     ]
    }
   ],
   "source": [
    "# do training\n",
    "num_model.fit(trainX_num, trainY, epochs=100, batch_size=256, shuffle=True, \n",
    "                  verbose=1, validation_split=0.1, callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)])\n",
    "\n",
    "# save model\n",
    "filepath = \"num_model_weights.h5\"\n",
    "num_model.save_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T06:20:18.196191Z",
     "start_time": "2017-11-14T06:20:15.183582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models weights loaded\n"
     ]
    }
   ],
   "source": [
    "# load models from file\n",
    "num_model.load_weights(\"num_model_weights.h5\")\n",
    "description_model.load_weights(\"description_model_weights.h5\")\n",
    "print(\"models weights loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T06:20:18.393641Z",
     "start_time": "2017-11-14T06:20:18.386929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x1c851257b8>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pop the original output value and replace with a dropout layer\n",
    "num_model.layers.pop()\n",
    "# x = Dropout(0.25)(num_model.layers[-1].output)\n",
    "# num_model = Model(inputs=[num_model.layers[0].input], outputs=[x])\n",
    "description_model.layers.pop()\n",
    "# x = Dropout(0.5)(description_model.layers[-1].output)\n",
    "# description_model = Model(inputs=[description_model.layers[0].input], outputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T06:20:18.713009Z",
     "start_time": "2017-11-14T06:20:18.573257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_43/Sigmoid:0' shape=(?, 64) dtype=float32>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "description_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "description_model.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T06:35:46.265801Z",
     "start_time": "2017-11-14T06:35:46.104204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 816\n",
      "Trainable params: 720\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "num_model summary None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "embedding_28 (Embedding)     (None, 40, 64)            5240192   \n",
      "_________________________________________________________________\n",
      "gaussian_noise_16 (GaussianN (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 36, 64)            20544     \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 36, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 34, 64)            12352     \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 34, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 17, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 64)                69696     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 5,343,040\n",
      "Trainable params: 5,342,912\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "desc_model summary None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 40, 64)       5240192     input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_16 (GaussianNois (None, 40, 64)       0           embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 36, 64)       20544       gaussian_noise_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 36, 64)       0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 32)           96          input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 34, 64)       12352       dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 32)           128         dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 34, 64)       0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 32)           0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 17, 64)       0           dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 32)           0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 1088)         0           max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 16)           528         dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 64)           69696       flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16)           64          dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 64)           256         dense_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16)           0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 64)           0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 80)           0           activation_45[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "model_46 (Model)                (None, 1)            81          concatenate_25[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 5,343,937\n",
      "Trainable params: 5,343,713\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "hybrid model summary\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# build hybrid model\n",
    "# merge models\n",
    "hybrid_output = concatenate([num_model.layers[-1].output, description_model.layers[-1].output])\n",
    "# create lower part of the model\n",
    "model_input = Input(shape=(80,))\n",
    "# output = Dense(units=64)(model_input)\n",
    "# output = Activation(\"sigmoid\")(output)\n",
    "# output = Dropout(0.5)(output)\n",
    "# output = BatchNormalization()(output)\n",
    "# output = Activation(\"sigmoid\")(output)\n",
    "# output = Dense(units=1, activation=\"sigmoid\")(output)\n",
    "output = Dense(units=1, activation=\"sigmoid\")(model_input)\n",
    "lower_model = Model(inputs=[model_input], outputs=[output])\n",
    "# concatenate two models\n",
    "hybrid_model = Model(inputs=[num_model.layers[0].input, description_model.layers[0].input], outputs=[lower_model(hybrid_output)])\n",
    "\n",
    "# compile for training\n",
    "hybrid_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = ['accuracy'])\n",
    "print(\"num_model summary\", num_model.summary())\n",
    "print(\"desc_model summary\", description_model.summary())\n",
    "print(\"hybrid model summary\\n\", hybrid_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T06:40:43.819019Z",
     "start_time": "2017-11-14T06:35:47.566214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87584 samples, validate on 9732 samples\n",
      "Epoch 1/1\n",
      "87584/87584 [==============================] - 53s 601us/step - loss: 0.1817 - acc: 0.9499 - val_loss: 0.7390 - val_acc: 0.7379\n",
      "10813/10813 [==============================] - 1s 90us/step\n",
      "Accuracy:[ 0.74291515  0.73735319]\n",
      "actual epoch num is:  0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 40, 64)       5240192     input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_16 (GaussianNois (None, 40, 64)       0           embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 36, 64)       20544       gaussian_noise_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 36, 64)       0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 32)           96          input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 34, 64)       12352       dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 32)           128         dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 34, 64)       0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 32)           0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 17, 64)       0           dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 32)           0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 1088)         0           max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 16)           528         dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 64)           69696       flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16)           64          dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 64)           256         dense_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16)           0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 64)           0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 80)           0           activation_45[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "model_46 (Model)                (None, 1)            81          concatenate_25[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 5,343,937\n",
      "Trainable params: 5,343,632\n",
      "Non-trainable params: 305\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 87584 samples, validate on 9732 samples\n",
      "Epoch 1/10\n",
      "87584/87584 [==============================] - 54s 612us/step - loss: 0.0946 - acc: 0.9655 - val_loss: 0.8016 - val_acc: 0.7385\n",
      "Epoch 2/10\n",
      "87584/87584 [==============================] - 53s 602us/step - loss: 0.0857 - acc: 0.9675 - val_loss: 0.8250 - val_acc: 0.7494\n",
      "Epoch 3/10\n",
      "87584/87584 [==============================] - 54s 611us/step - loss: 0.0768 - acc: 0.9714 - val_loss: 0.8504 - val_acc: 0.7375\n",
      "10813/10813 [==============================] - 1s 115us/step\n",
      "Accuracy:[ 0.85882944  0.73485619]\n",
      "actual epoch num is:  0\n",
      "Train on 87584 samples, validate on 9732 samples\n",
      "Epoch 1/10\n",
      "87584/87584 [==============================] - 50s 571us/step - loss: 0.0750 - acc: 0.9717 - val_loss: 0.8526 - val_acc: 0.7488\n",
      "Epoch 2/10\n",
      "48128/87584 [===============>..............] - ETA: 22s - loss: 0.0713 - acc: 0.9738"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-214-99f70c563901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     hybrid_model.fit([trainX_num, trainX_desc], trainY, epochs=10, batch_size=256, shuffle=True, \n\u001b[0;32m---> 17\u001b[0;31m                   verbose=1, validation_split=0.1, callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=2)])\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# see actual result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhybrid_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestX_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX_desc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# do training\n",
    "# do pretraining:\n",
    "hybrid_model.fit([trainX_num, trainX_desc], trainY, epochs=1, batch_size=256, shuffle=True, \n",
    "                  verbose=1, validation_split=0.1, callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=2)])\n",
    "# see actual result\n",
    "scores = hybrid_model.evaluate([testX_num, testX_desc], testY, verbose=1)\n",
    "print(\"Accuracy:{}\".format(np.array(scores)))\n",
    "print(\"actual epoch num is: \", i)\n",
    "\n",
    "hybrid_model.layers[-1].trainable = False\n",
    "hybrid_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = ['accuracy'])\n",
    "print(hybrid_model.summary())\n",
    "\n",
    "epoch_num = 5\n",
    "for i in range(epoch_num):\n",
    "    hybrid_model.fit([trainX_num, trainX_desc], trainY, epochs=10, batch_size=256, shuffle=True, \n",
    "                  verbose=1, validation_split=0.1, callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=2)])\n",
    "    # see actual result\n",
    "    scores = hybrid_model.evaluate([testX_num, testX_desc], testY, verbose=1)\n",
    "    print(\"Accuracy:{}\".format(np.array(scores)))\n",
    "    print(\"actual epoch num is: \", i)\n",
    "\n",
    "# save model\n",
    "filepath = \"hybrid_model_weights.h5\"\n",
    "hybrid_model.save_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T06:14:22.065099Z",
     "start_time": "2017-11-14T06:14:21.185275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10813/10813 [==============================] - 1s 76us/step\n",
      "Accuracy:[ 1.27852129  0.71247572]\n"
     ]
    }
   ],
   "source": [
    "hybrid_model.load_weights(\"hybrid_model_weights.h5\")\n",
    "scores = hybrid_model.evaluate([testX_num, testX_desc], testY, verbose=1)\n",
    "print(\"Accuracy:{}\".format(np.array(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 278,
   "position": {
    "height": "40px",
    "left": "1140px",
    "right": "63px",
    "top": "189px",
    "width": "477px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
